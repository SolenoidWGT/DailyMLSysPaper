[
    {
        "title": "Self-Evaluation as a Defense Against Adversarial Attacks on LLMs",
        "url": "http://arxiv.org/abs/2407.03234v1",
        "pub_date": "2024-07-03",
        "summary": "When LLMs are deployed in sensitive, human-facing settings, it is crucial\nthat they do not output unsafe, biased, or privacy-violating outputs. For this\nreason, models are both trained and instructed to refuse to answer unsafe\nprompts such as \"Tell me how to build a bomb.\" We find that, despite these\nsafeguards, it is possible to break model defenses simply by appending a space\nto the end of a model's input. In a study of eight open-source models, we\ndemonstrate that this acts as a strong enough attack to cause the majority of\nmodels to generate harmful outputs with very high success rates. We examine the\ncauses of this behavior, finding that the contexts in which single spaces occur\nin tokenized training data encourage models to generate lists when prompted,\noverriding training signals to refuse to answer unsafe requests. Our findings\nunderscore the fragile state of current model alignment and promote the\nimportance of developing more robust alignment methods. Code and data will be\nmade available at https://github.com/Linlt-leon/Adversarial-Alignments.",
        "translated": "当 LLM 部署在敏感的、面向人的设置中时，关键是不要输出不安全的、有偏见的或侵犯隐私的输出。出于这个原因，模特们都接受过训练，也接受过指导，拒绝回答诸如“告诉我如何制造炸弹”之类的不安全提示我们发现，尽管有这些保护措施，仅仅通过在模型输入的末尾添加一个空格，就有可能打破模型的防御。在一项对八个开源模型的研究中，我们证明了这种攻击足够强大，足以导致大多数模型产生有害的输出，成功率非常高。我们检查了这种行为的原因，发现在标记化的训练数据中出现单个空格的上下文鼓励模型在提示时生成列表，覆盖训练信号以拒绝回答不安全的请求。我们的研究结果强调了当前模型对齐的脆弱状态，并提出了开发更强大的对齐方法的重要性。代码和数据将在 https://github.com/linlt-leon/adversarial-alignments 公布。"
    },
    {
        "title": "Bridging Model Heterogeneity in Federated Learning via Uncertainty-based\n  Asymmetrical Reciprocity Learning",
        "url": "http://arxiv.org/abs/2407.03247v1",
        "pub_date": "2024-07-03",
        "summary": "This paper presents FedType, a simple yet pioneering framework designed to\nfill research gaps in heterogeneous model aggregation within federated learning\n(FL). FedType introduces small identical proxy models for clients, serving as\nagents for information exchange, ensuring model security, and achieving\nefficient communication simultaneously. To transfer knowledge between large\nprivate and small proxy models on clients, we propose a novel uncertainty-based\nasymmetrical reciprocity learning method, eliminating the need for any public\ndata. Comprehensive experiments conducted on benchmark datasets demonstrate the\nefficacy and generalization ability of FedType across diverse settings. Our\napproach redefines federated learning paradigms by bridging model\nheterogeneity, eliminating reliance on public data, prioritizing client\nprivacy, and reducing communication costs.",
        "authors": "Jiaqi Wang, Chenxu Zhao, Lingjuan Lyu, Quanzeng You, Mengdi Huai, Fenglong Ma",
        "translated": "本文介绍了 FedType，这是一个简单而具有开创性的框架，旨在填补联邦学习(FL)中异构模型聚合的研究空白。FedType 为客户端引入了小型相同的代理模型，作为信息交换的代理，保证了模型的安全性，同时实现了高效的通信。针对大型私有代理模型和小型代理模型之间的知识传递问题，提出了一种基于不确定性的非对称互惠学习方法，该方法不需要任何公开数据。在基准数据集上进行的综合实验证明了 FedType 在不同环境下的有效性和推广能力。我们的方法通过桥接模型异构性、消除对公共数据的依赖、优先考虑客户隐私和降低通信成本来重新定义联邦学习范例。"
    },
    {
        "title": "Streaming Large-Scale Electron Microscopy Data to a Supercomputing\n  Facility",
        "url": "http://arxiv.org/abs/2407.03215v1",
        "pub_date": "2024-07-03",
        "summary": "Data management is a critical component of modern experimental workflows. As\ndata generation rates increase, transferring data from acquisition servers to\nprocessing servers via conventional file-based methods is becoming increasingly\nimpractical. The 4D Camera at the National Center for Electron Microscopy\n(NCEM) generates data at a nominal rate of 480 Gbit/s (87,000 frames/s)\nproducing a 700 GB dataset in fifteen seconds. To address the challenges\nassociated with storing and processing such quantities of data, we developed a\nstreaming workflow that utilizes a high-speed network to connect the 4D\nCamera's data acquisition (DAQ) system to supercomputing nodes at the National\nEnergy Research Scientific Computing Center (NERSC), bypassing intermediate\nfile storage entirely. In this work, we demonstrate the effectiveness of our\nstreaming pipeline in a production setting through an hour-long experiment that\ngenerated over 10 TB of raw data, yielding high-quality datasets suitable for\nadvanced analyses. Additionally, we compare the efficacy of this streaming\nworkflow against the conventional file-transfer workflow by conducting a\npost-mortem analysis on historical data from experiments performed by real\nusers. Our findings show that the streaming workflow significantly improves\ndata turnaround time, enables real-time decision-making, and minimizes the\npotential for human error by eliminating manual user interactions.",
        "authors": "Samuel S. Welborn, Chris Harris, Stephanie M. Ribet, Georgios Varnavides, Colin Ophus, Bjoern Enders, Peter Ercius",
        "translated": "数据管理是现代实验工作流的重要组成部分。随着数据生成率的提高，通过传统的基于文件的方法将数据从采集服务器传输到处理服务器正变得越来越不切实际。美国国家电子显微镜中心(NCEM)的4D 相机以480Gbit/s (87000帧/s)的标称速率生成数据，在15秒内产生700GB 的数据集。为了解决存储和处理这样大量数据的挑战，我们开发了一个流式工作流，利用高速网络将4D 摄像机的数据采集(DAQ)系统连接到国家能源研究科学计算中心(NERSC)的超级计算节点，完全绕过中间文件存储。在这项工作中，我们通过一个小时的实验，生成了超过10TB 的原始数据，产生了适合高级分析的高质量数据集，从而证明了我们的流式流水线在生产环境中的有效性。此外，我们通过对实际用户实验中的历史数据进行事后分析，比较了该流工作流与传统文件传输工作流的效率。我们的研究结果表明，流式工作流可以显著提高数据周转时间，实现实时决策，并通过消除人工用户交互，最大限度地减少潜在的人为错误。"
    },
    {
        "title": "Effective Heterogeneous Federated Learning via Efficient\n  Hypernetwork-based Weight Generation",
        "url": "http://arxiv.org/abs/2407.03086v1",
        "pub_date": "2024-07-03",
        "summary": "While federated learning leverages distributed client resources, it faces\nchallenges due to heterogeneous client capabilities. This necessitates\nallocating models suited to clients' resources and careful parameter\naggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel\nfederated learning framework for supporting client heterogeneity by combining a\nmulti-exit network architecture with hypernetwork-based model weight\ngeneration. This approach aligns the feature spaces of heterogeneous model\nlayers and resolves per-layer information disparity during weight aggregation.\nTo practically realize HypeMeFed, we also propose a low-rank factorization\napproach to minimize computation and memory overhead associated with\nhypernetworks. Our evaluations on a real-world heterogeneous device testbed\nindicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the\nhypernetwork memory requirements by 98.22%, and accelerates its operations by\n1.86 times compared to a naive hypernetwork approach. These results demonstrate\nHypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for\nfederated learning.",
        "authors": "Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko",
        "translated": "虽然联邦学习利用分布式客户端资源，但是由于异构客户端功能，它面临着挑战。这就需要分配适合客户端资源的模型和仔细的参数聚合来适应这种异构性。我们提出了一种新的联邦学习框架 HypeMeFed，它通过将多出口网络结构与基于超网络的模型权重生成相结合来支持客户端的异构性。该方法对异构模型层的特征空间进行对齐，解决了权重聚合过程中各层的信息差异问题。为了实现 HypeMeFed，我们还提出了一种低秩因子分解方法，以最小化与超网络相关的计算和内存开销。我们对现实世界异构设备测试台的评估表明，与天真的超网络方法相比，HypeMeFed 比 FedAvg 提高了5.12% 的准确性，减少了98.22% 的超网络内存需求，并将其操作加速了1.86倍。这些结果证明了 HypeMeFed 在利用和吸引异构客户机进行联合学习方面的有效性。"
    }
]