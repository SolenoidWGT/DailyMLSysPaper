[
    {
        "title": "Self-Evaluation as a Defense Against Adversarial Attacks on LLMs",
        "url": "http://arxiv.org/abs/2407.03234v1",
        "pub_date": "2024-07-03",
        "summary": "When LLMs are deployed in sensitive, human-facing settings, it is crucial\nthat they do not output unsafe, biased, or privacy-violating outputs. For this\nreason, models are both trained and instructed to refuse to answer unsafe\nprompts such as \"Tell me how to build a bomb.\" We find that, despite these\nsafeguards, it is possible to break model defenses simply by appending a space\nto the end of a model's input. In a study of eight open-source models, we\ndemonstrate that this acts as a strong enough attack to cause the majority of\nmodels to generate harmful outputs with very high success rates. We examine the\ncauses of this behavior, finding that the contexts in which single spaces occur\nin tokenized training data encourage models to generate lists when prompted,\noverriding training signals to refuse to answer unsafe requests. Our findings\nunderscore the fragile state of current model alignment and promote the\nimportance of developing more robust alignment methods. Code and data will be\nmade available at https://github.com/Linlt-leon/Adversarial-Alignments.",
        "translated": "当 LLM 部署在敏感的、面向人的设置中时，关键是不要输出不安全的、有偏见的或侵犯隐私的输出。出于这个原因，模特们都接受过训练，也接受过指导，拒绝回答诸如“告诉我如何制造炸弹”之类的不安全提示我们发现，尽管有这些保护措施，仅仅通过在模型输入的末尾添加一个空格，就有可能打破模型的防御。在一项对八个开源模型的研究中，我们证明了这种攻击足够强大，足以导致大多数模型产生有害的输出，成功率非常高。我们检查了这种行为的原因，发现在标记化的训练数据中出现单个空格的上下文鼓励模型在提示时生成列表，覆盖训练信号以拒绝回答不安全的请求。我们的研究结果强调了当前模型对齐的脆弱状态，并提出了开发更强大的对齐方法的重要性。代码和数据将在 https://github.com/linlt-leon/adversarial-alignments 公布。"
    },
    {
        "title": "Bridging Model Heterogeneity in Federated Learning via Uncertainty-based\n  Asymmetrical Reciprocity Learning",
        "url": "http://arxiv.org/abs/2407.03247v1",
        "pub_date": "2024-07-03",
        "summary": "This paper presents FedType, a simple yet pioneering framework designed to\nfill research gaps in heterogeneous model aggregation within federated learning\n(FL). FedType introduces small identical proxy models for clients, serving as\nagents for information exchange, ensuring model security, and achieving\nefficient communication simultaneously. To transfer knowledge between large\nprivate and small proxy models on clients, we propose a novel uncertainty-based\nasymmetrical reciprocity learning method, eliminating the need for any public\ndata. Comprehensive experiments conducted on benchmark datasets demonstrate the\nefficacy and generalization ability of FedType across diverse settings. Our\napproach redefines federated learning paradigms by bridging model\nheterogeneity, eliminating reliance on public data, prioritizing client\nprivacy, and reducing communication costs.",
        "authors": "Jiaqi Wang, Chenxu Zhao, Lingjuan Lyu, Quanzeng You, Mengdi Huai, Fenglong Ma",
        "translated": "本文介绍了 FedType，这是一个简单而具有开创性的框架，旨在填补联邦学习(FL)中异构模型聚合的研究空白。FedType 为客户端引入了小型相同的代理模型，作为信息交换的代理，保证了模型的安全性，同时实现了高效的通信。针对大型私有代理模型和小型代理模型之间的知识传递问题，提出了一种基于不确定性的非对称互惠学习方法，该方法不需要任何公开数据。在基准数据集上进行的综合实验证明了 FedType 在不同环境下的有效性和推广能力。我们的方法通过桥接模型异构性、消除对公共数据的依赖、优先考虑客户隐私和降低通信成本来重新定义联邦学习范例。"
    },
    {
        "title": "Streaming Large-Scale Electron Microscopy Data to a Supercomputing\n  Facility",
        "url": "http://arxiv.org/abs/2407.03215v1",
        "pub_date": "2024-07-03",
        "summary": "Data management is a critical component of modern experimental workflows. As\ndata generation rates increase, transferring data from acquisition servers to\nprocessing servers via conventional file-based methods is becoming increasingly\nimpractical. The 4D Camera at the National Center for Electron Microscopy\n(NCEM) generates data at a nominal rate of 480 Gbit/s (87,000 frames/s)\nproducing a 700 GB dataset in fifteen seconds. To address the challenges\nassociated with storing and processing such quantities of data, we developed a\nstreaming workflow that utilizes a high-speed network to connect the 4D\nCamera's data acquisition (DAQ) system to supercomputing nodes at the National\nEnergy Research Scientific Computing Center (NERSC), bypassing intermediate\nfile storage entirely. In this work, we demonstrate the effectiveness of our\nstreaming pipeline in a production setting through an hour-long experiment that\ngenerated over 10 TB of raw data, yielding high-quality datasets suitable for\nadvanced analyses. Additionally, we compare the efficacy of this streaming\nworkflow against the conventional file-transfer workflow by conducting a\npost-mortem analysis on historical data from experiments performed by real\nusers. Our findings show that the streaming workflow significantly improves\ndata turnaround time, enables real-time decision-making, and minimizes the\npotential for human error by eliminating manual user interactions.",
        "authors": "Samuel S. Welborn, Chris Harris, Stephanie M. Ribet, Georgios Varnavides, Colin Ophus, Bjoern Enders, Peter Ercius",
        "translated": "数据管理是现代实验工作流的重要组成部分。随着数据生成率的提高，通过传统的基于文件的方法将数据从采集服务器传输到处理服务器正变得越来越不切实际。美国国家电子显微镜中心(NCEM)的4D 相机以480Gbit/s (87000帧/s)的标称速率生成数据，在15秒内产生700GB 的数据集。为了解决存储和处理这样大量数据的挑战，我们开发了一个流式工作流，利用高速网络将4D 摄像机的数据采集(DAQ)系统连接到国家能源研究科学计算中心(NERSC)的超级计算节点，完全绕过中间文件存储。在这项工作中，我们通过一个小时的实验，生成了超过10TB 的原始数据，产生了适合高级分析的高质量数据集，从而证明了我们的流式流水线在生产环境中的有效性。此外，我们通过对实际用户实验中的历史数据进行事后分析，比较了该流工作流与传统文件传输工作流的效率。我们的研究结果表明，流式工作流可以显著提高数据周转时间，实现实时决策，并通过消除人工用户交互，最大限度地减少潜在的人为错误。"
    },
    {
        "title": "Effective Heterogeneous Federated Learning via Efficient\n  Hypernetwork-based Weight Generation",
        "url": "http://arxiv.org/abs/2407.03086v1",
        "pub_date": "2024-07-03",
        "summary": "While federated learning leverages distributed client resources, it faces\nchallenges due to heterogeneous client capabilities. This necessitates\nallocating models suited to clients' resources and careful parameter\naggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel\nfederated learning framework for supporting client heterogeneity by combining a\nmulti-exit network architecture with hypernetwork-based model weight\ngeneration. This approach aligns the feature spaces of heterogeneous model\nlayers and resolves per-layer information disparity during weight aggregation.\nTo practically realize HypeMeFed, we also propose a low-rank factorization\napproach to minimize computation and memory overhead associated with\nhypernetworks. Our evaluations on a real-world heterogeneous device testbed\nindicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the\nhypernetwork memory requirements by 98.22%, and accelerates its operations by\n1.86 times compared to a naive hypernetwork approach. These results demonstrate\nHypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for\nfederated learning.",
        "authors": "Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko",
        "translated": "虽然联邦学习利用分布式客户端资源，但是由于异构客户端功能，它面临着挑战。这就需要分配适合客户端资源的模型和仔细的参数聚合来适应这种异构性。我们提出了一种新的联邦学习框架 HypeMeFed，它通过将多出口网络结构与基于超网络的模型权重生成相结合来支持客户端的异构性。该方法对异构模型层的特征空间进行对齐，解决了权重聚合过程中各层的信息差异问题。为了实现 HypeMeFed，我们还提出了一种低秩因子分解方法，以最小化与超网络相关的计算和内存开销。我们对现实世界异构设备测试台的评估表明，与天真的超网络方法相比，HypeMeFed 比 FedAvg 提高了5.12% 的准确性，减少了98.22% 的超网络内存需求，并将其操作加速了1.86倍。这些结果证明了 HypeMeFed 在利用和吸引异构客户机进行联合学习方面的有效性。"
    },
    {
        "title": "On the Client Preference of LLM Fine-tuning in Federated Learning",
        "url": "http://arxiv.org/abs/2407.03038v1",
        "pub_date": "2024-07-03",
        "summary": "Reinforcement learning with human feedback (RLHF) fine-tunes a pretrained\nlarge language model (LLM) using preference datasets, enabling the LLM to\ngenerate outputs that align with human preferences. Given the sensitive nature\nof these preference datasets held by various clients, there is a need to\nimplement RLHF within a federated learning (FL) framework, where clients are\nreluctant to share their data due to privacy concerns. To address this, we\nintroduce a feasible framework in which clients collaboratively train a binary\nselector with their preference datasets using our proposed FedBis. With a\nwell-trained selector, we can further enhance the LLM that generates\nhuman-preferred completions. Meanwhile, we propose a novel algorithm,\nFedBiscuit, that trains multiple selectors by organizing clients into balanced\nand disjoint clusters based on their preferences. Compared to the FedBis,\nFedBiscuit demonstrates superior performance in simulating human preferences\nfor pairwise completions. Our extensive experiments on federated human\npreference datasets -- marking the first benchmark to address heterogeneous\ndata partitioning among clients -- demonstrate that FedBiscuit outperforms\nFedBis and even surpasses traditional centralized training.",
        "authors": "Feijie Wu, Xiaoze Liu, Haoyu Wang, Xingchen Wang, Jing Gao",
        "translated": "强化学习反馈(rlHF)使用偏好数据集对预先训练好的大语言模型(LLM)进行微调，使 LLM 能够生成符合人类偏好的输出。鉴于这些偏好数据集由不同的客户端持有的敏感性质，有必要在联邦学习(FL)框架内实现 RLHF，其中客户端由于隐私问题不愿意共享他们的数据。为了解决这个问题，我们引入了一个可行的框架，在这个框架中，客户端使用我们提出的 FedBis 协作地训练一个二进制选择器和他们的偏好数据集。使用训练有素的选择器，我们可以进一步增强生成人类首选完成的 LLM。同时，我们提出了一种新的算法，FedBiscookie，通过将客户端根据他们的偏好组织成平衡的和不相交的集群来训练多个选择器。与 FedBis 相比，FedBiscookie 在模拟人类对配对完成的偏好方面表现出了优越的性能。我们在联邦人类偏好数据集上的广泛实验——标志着解决客户端之间异构数据分区的第一个基准——证明了 FedBiscue 的性能优于 FedBis，甚至超过了传统的集中式训练。"
    },
    {
        "title": "DRLQ: A Deep Reinforcement Learning-based Task Placement for Quantum\n  Cloud Computing",
        "url": "http://arxiv.org/abs/2407.02748v1",
        "pub_date": "2024-07-03",
        "summary": "The quantum cloud computing paradigm presents unique challenges in task\nplacement due to the dynamic and heterogeneous nature of quantum computation\nresources. Traditional heuristic approaches fall short in adapting to the\nrapidly evolving landscape of quantum computing. This paper proposes DRLQ, a\nnovel Deep Reinforcement Learning (DRL)-based technique for task placement in\nquantum cloud computing environments, addressing the optimization of task\ncompletion time and quantum task scheduling efficiency. It leverages the Deep Q\nNetwork (DQN) architecture, enhanced with the Rainbow DQN approach, to create a\ndynamic task placement strategy. This approach is one of the first in the field\nof quantum cloud resource management, enabling adaptive learning and\ndecision-making for quantum cloud environments and effectively optimizing task\nplacement based on changing conditions and resource availability. We conduct\nextensive experiments using the QSimPy simulation toolkit to evaluate the\nperformance of our method, demonstrating substantial improvements in task\nexecution efficiency and a reduction in the need to reschedule quantum tasks.\nOur results show that utilizing the DRLQ approach for task placement can\nsignificantly reduce total quantum task completion time by 37.81% to 72.93% and\nprevent task rescheduling attempts compared to other heuristic approaches.",
        "authors": "Hoa T. Nguyen, Muhammad Usman, Rajkumar Buyya",
        "translated": "由于量子计算资源的动态性和异构性，量子云计算范式在任务配置中提出了独特的挑战。传统的启发式方法不能适应量子计算的快速发展。本文提出了基于深度强化学习的量子云计算任务分配技术 DRLQ，解决了任务完成时间和量子任务调度效率的优化问题。它利用 Deep Q Network (DQN)体系结构，并通过 Rainbow DQN 方法得到了增强，从而创建了一个动态任务分配策略。这种方法是量子云资源管理领域的首创之一，能够为量子云环境提供在线机机器学习和决策支持，并根据不断变化的条件和资源可用性有效地优化任务分配。我们使用 QSimPy 模拟工具包进行了广泛的实验，以评估我们的方法的性能，证明了任务执行效率的实质性改进和重新调度量子任务的需求的减少。实验结果表明，与其他启发式方法相比，利用 DRLQ 方法进行任务分配可以显著减少任务完成总时间37.81% 到72.93% ，并且可以防止任务重调度尝试。"
    }
]